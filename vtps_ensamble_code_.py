# -*- coding: utf-8 -*-
"""VTPs_Ensamble_Code .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1y0o5c-tXBa0wr3QtRfstKnvkt5iNBYPf
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import re
import os
from sklearn.neural_network import MLPClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.gaussian_process.kernels import RBF
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis
from sklearn.metrics import classification_report
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix
from sklearn.metrics import multilabel_confusion_matrix
from statistics import mean
import math
from sklearn.metrics import accuracy_score
from sklearn.metrics import roc_auc_score
from sklearn.metrics import roc_curve, auc, roc_auc_score
from sklearn.metrics import roc_curve
from sklearn.metrics import matthews_corrcoef
from lightgbm import LGBMClassifier
from xgboost import XGBClassifier
from lightgbm import LGBMClassifier
from sklearn.ensemble import StackingClassifier
from sklearn.ensemble import BaggingClassifier, ExtraTreesClassifier
from sklearn.linear_model import LogisticRegression
import seaborn as sns
import matplotlib.pyplot as plt
from collections import Counter
import seaborn as sns
from sklearn.manifold import TSNE
from __future__ import print_function
import time
import numpy as np
import pandas as pd
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE
# %matplotlib inline
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
import seaborn as sns

from google.colab import drive
drive.mount('/content/drive')

"""# **Basic Standerization**"""

from sklearn.preprocessing import StandardScaler

import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
import matplotlib.pyplot as plt

# Load your dataset (replace 'your_dataset.csv' with your actual file path)
#ds = pd.read_csv('/content/drive/MyDrive/FV-cdHitDone-newFVcode_park_p100000_n50k_0.70.csv')

import pandas as pd
import numpy as np

# Load your dataset
dataset = pd.read_csv('/content/drive/MyDrive/vesicularnew.csv', sep=',',header=None)

def replace_text_in_dataframe(text, replacement, dataframe):
    return dataframe.applymap(lambda x: replacement if str(x) == text else x)

search_text = '#NAME?'
replacement = 0
dataset = replace_text_in_dataframe(search_text, replacement, dataset)

numeric_cols = dataset.select_dtypes(include=[np.number])

# Replace NaN values with the minimum value in each numeric column
dataset[numeric_cols.columns] = numeric_cols.fillna(numeric_cols.min())

# Replace infinity values with the maximum value in each numeric column
for column in numeric_cols.columns:
    max_value = dataset[column].max()
    dataset[column].replace([np.inf, -np.inf], max_value, inplace=True)

# Separate features (X) and target variable (y)
X = dataset.iloc[:, :-1].values  # Assuming the last column is the target variable
y = dataset.iloc[:, -1].values

y

from sklearn.preprocessing import StandardScaler, MinMaxScaler
import numpy as np

std_scale = MinMaxScaler()
X = np.nan_to_num(X.astype('float32'))
X_scaled = std_scale.fit_transform(X)

from keras.models import Sequential
from keras.layers import Dense, Dropout
from keras.utils import to_categorical

# Assuming `X` and `y` are already defined and preprocessed
y_categorical = to_categorical(y)

# Define a simple feedforward neural network
model = Sequential()
model.add(Dense(128, input_dim=X.shape[1], activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(64, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(y_categorical.shape[1], activation='softmax'))

model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

# Train the model
model.fit(X, y_categorical, epochs=50, batch_size=32, verbose=1, validation_split=0.2)

from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve

# Evaluate model
y_pred = model.predict(X)
y_pred_classes = np.argmax(y_pred, axis=1)

print("Confusion Matrix:")
print(confusion_matrix(y, y_pred_classes))
print("Classification Report:")
print(classification_report(y, y_pred_classes))

# Calculate ROC and AUC
ns_probs_dl = [0 for _ in range(len(y))]
lr_probs_dl = y_pred[:, 1]

ns_fpr_dl, ns_tpr_dl, _ = roc_curve(y, ns_probs_dl)
lr_fpr_dl, lr_tpr_dl, _ = roc_curve(y, lr_probs_dl)
auc_score_dl = round(roc_auc_score(y, lr_probs_dl), 2)

print('AUC Score:', auc_score_dl)

import matplotlib.pyplot as plt

plt.figure(figsize=(10, 8))
plt.plot(ns_fpr1, ns_tpr1, linestyle='--', label='No Skill RF')
plt.plot(lr_fpr1, lr_tpr1, marker='.', color='green', label='RF AUC :{:.2f}'.format(auc_score))

plt.plot(ns_fpr2, ns_tpr2, linestyle='--', label='No Skill LGBM')
plt.plot(lr_fpr2, lr_tpr2, marker='.', color='blue', label='LGBM AUC :{:.2f}'.format(auc_score2))

plt.plot(ns_fpr3, ns_tpr3, linestyle='--', label='No Skill XGB')
plt.plot(lr_fpr3, lr_tpr3, marker='.', color='yellow', label='XGB AUC :{:.2f}'.format(auc_score3))

plt.plot(ns_fpr4, ns_tpr4, linestyle='--', label='No Skill ET')
plt.plot(lr_fpr4, lr_tpr4, marker='.', color='red', label='ET AUC :{:.2f}'.format(auc_score4))

plt.plot(ns_fpr5, ns_tpr5, linestyle='--', label='No Skill Stacking')
plt.plot(lr_fpr5, lr_tpr5, marker='.', color='pink', label='Stacking AUC :{:.2f}'.format(auc_score5))

plt.plot(ns_fpr6, ns_tpr6, linestyle='--', label='No Skill Bagging')
plt.plot(lr_fpr6, lr_tpr6, marker='.', color='orange', label='Bagging AUC :{:.2f}'.format(auc_score6))

# Add Deep Learning ROC Curve
plt.plot(ns_fpr_dl, ns_tpr_dl, linestyle='--', label='No Skill DL')
plt.plot(lr_fpr_dl, lr_tpr_dl, marker='.', color='purple', label='DL AUC :{:.2f}'.format(auc_score_dl))

plt.plot([0, 1], [0, 1], color='black', lw=1, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc='lower right')
plt.show()

"""# Self-**Consistency**"""

clf2=LGBMClassifier()
clf1=RandomForestClassifier(n_estimators=100, max_depth=50, oob_score=True, n_jobs=-1, warm_start=True)
clf3 = XGBClassifier(n_estimators=100, max_depth=9, learning_rate=0.1)
clf4=ExtraTreesClassifier(n_estimators=100, max_depth=None, min_samples_split=2)
clf6= BaggingClassifier()

lr = LogisticRegression(random_state=42)

# Define your stacking classifier with the base learners and meta-learner
clf5 = StackingClassifier(
    estimators=[('xgb', clf3),('rf', clf1) ],final_estimator=lr)

print('Self-Consistency Random Forest')
clf = clf1.fit(X, y)
pred=np.round(clf.predict(X))
tn, fp, fn, tp = confusion_matrix(y, pred, labels=[1, 0]).ravel()
acc = np.round(((tn + tp) / (tn + fp + fn + tp)) * 100, 2)
sp = np.round((tn / (fp + tn)) * 100, 2)
sn = np.round((tp / (tp + fn)) * 100, 2)
mcc = np.round(matthews_corrcoef(y, pred), 5)
pre = np.round((tp / (tp + fp)) * 100, 2)
f1 = np.round(2 * (pre * sn) / (pre + sn), 2)
print("Accuracy: " + str(acc))
print("Sensitivity/Recall: " + str(sn))
print("Specificity: " + str(sp))
print("MCC: " + str(mcc))
print("Precision: " + str(pre))
print("F1_Score: " + str(f1))

ns_probs=[0 for _ in range(len(y))]
lr_probs=clf.predict_proba(X)
# keep probabilities for the positive outcome only
lr_probs=lr_probs[:, 1]

# calculate roc curves
ns_fpr1, ns_tpr1, _=roc_curve(y, ns_probs)
lr_fpr1, lr_tpr1, _=roc_curve(y, lr_probs)
auc_score = round(roc_auc_score(y, lr_probs),2)

print('Self-Consistency LGBM')
clf=clf2.fit(X, y)
pred=np.round(clf.predict(X))
tn, fp, fn, tp = confusion_matrix(y, pred, labels=[1, 0]).ravel()
acc = np.round(((tn + tp) / (tn + fp + fn + tp)) * 100, 2)
sp = np.round((tn / (fp + tn)) * 100, 2)
sn = np.round((tp / (tp + fn)) * 100, 2)
mcc = np.round(matthews_corrcoef(y, pred), 5)
pre = np.round((tp / (tp + fp)) * 100, 2)
f1 = np.round(2 * (pre * sn) / (pre + sn), 2)
print("Accuracy: " + str(acc))
print("Sensitivity/Recall: " + str(sn))
print("Specificity: " + str(sp))
print("MCC: " + str(mcc))
print("Precision: " + str(pre))
print("F1_Score: " + str(f1))

ns_probs2=[0 for _ in range(len(y))]
lr_probs2=clf.predict_proba(X)
# keep probabilities for the positive outcome only
lr_probs2=lr_probs2[:, 1]

# calculate roc curves
ns_fpr2, ns_tpr2, _=roc_curve(y, ns_probs2)
lr_fpr2, lr_tpr2, _=roc_curve(y, lr_probs2)
auc_score2 = round(roc_auc_score(y, lr_probs2),2)

print('Self-Consistency XGB')
clf=clf3.fit(X, y)
pred=np.round(clf.predict(X))
tn, fp, fn, tp = confusion_matrix(y, pred, labels=[1, 0]).ravel()
acc = np.round(((tn + tp) / (tn + fp + fn + tp)) * 100, 2)
sp = np.round((tn / (fp + tn)) * 100, 2)
sn = np.round((tp / (tp + fn)) * 100, 2)
mcc = np.round(matthews_corrcoef(y, pred), 5)
pre = np.round((tp / (tp + fp)) * 100, 2)
f1 = np.round(2 * (pre * sn) / (pre + sn), 2)
print("Accuracy: " + str(acc))
print("Sensitivity/Recall: " + str(sn))
print("Specificity: " + str(sp))
print("MCC: " + str(mcc))
print("Precision: " + str(pre))
print("F1_Score: " + str(f1))

ns_probs3=[0 for _ in range(len(y))]
lr_probs3=clf.predict_proba(X)
# keep probabilities for the positive outcome only
lr_probs3=lr_probs3[:, 1]

# calculate roc curves
ns_fpr3, ns_tpr3, _=roc_curve(y, ns_probs3)
lr_fpr3, lr_tpr3, _=roc_curve(y, lr_probs3)
auc_score3 = round(roc_auc_score(y, lr_probs3),2)


print('Self-Consistency ET')
clf=clf4.fit(X,y)
pred=np.round(clf.predict(X))
tn, fp, fn, tp = confusion_matrix(y, pred, labels=[1, 0]).ravel()
acc = np.round(((tn + tp) / (tn + fp + fn + tp)) * 100, 2)
sp = np.round((tn / (fp + tn)) * 100, 2)
sn = np.round((tp / (tp + fn)) * 100, 2)
mcc = np.round(matthews_corrcoef(y, pred), 5)
pre = np.round((tp / (tp + fp)) * 100, 2)
f1 = np.round(2 * (pre * sn) / (pre + sn), 2)
print("Accuracy: " + str(acc))
print("Sensitivity/Recall: " + str(sn))
print("Specificity: " + str(sp))
print("MCC: " + str(mcc))
print("Precision: " + str(pre))
print("F1_Score: " + str(f1))

ns_probs4=[0 for _ in range(len(y))]
lr_probs4=clf.predict_proba(X)
# keep probabilities for the positive outcome only
lr_probs4=lr_probs4[:, 1]

# calculate roc curves
ns_fpr4, ns_tpr4, _=roc_curve(y, ns_probs4)
lr_fpr4, lr_tpr4, _=roc_curve(y, lr_probs4)
auc_score4 = round(roc_auc_score(y, lr_probs4),2)

print('Self-Consistency Stacking')
clf=clf5.fit(X, y)
pred=np.round(clf.predict(X))
tn, fp, fn, tp = confusion_matrix(y, pred, labels=[1, 0]).ravel()
acc = np.round(((tn + tp) / (tn + fp + fn + tp)) * 100, 2)
sp = np.round((tn / (fp + tn)) * 100, 2)
sn = np.round((tp / (tp + fn)) * 100, 2)
mcc = np.round(matthews_corrcoef(y, pred), 5)
pre = np.round((tp / (tp + fp)) * 100, 2)
f1 = np.round(2 * (pre * sn) / (pre + sn), 2)
print("Accuracy: " + str(acc))
print("Sensitivity/Recall: " + str(sn))
print("Specificity: " + str(sp))
print("MCC: " + str(mcc))
print("Precision: " + str(pre))
print("F1_Score: " + str(f1))

ns_probs5=[0 for _ in range(len(y))]
lr_probs5=clf.predict_proba(X)
# keep probabilities for the positive outcome only
lr_probs5=lr_probs5[:, 1]

# calculate roc curves
ns_fpr5, ns_tpr5, _=roc_curve(y, ns_probs5)
lr_fpr5, lr_tpr5, _=roc_curve(y, lr_probs5)
auc_score5 = round(roc_auc_score(y, lr_probs5),2)



print('Self-Consistency Bagging')
clf=clf6.fit(X, y)
pred=np.round(clf.predict(X))
tn, fp, fn, tp = confusion_matrix(y, pred, labels=[1, 0]).ravel()
acc = np.round(((tn + tp) / (tn + fp + fn + tp)) * 100, 2)
sp = np.round((tn / (fp + tn)) * 100, 2)
sn = np.round((tp / (tp + fn)) * 100, 2)
mcc = np.round(matthews_corrcoef(y, pred), 5)
pre = np.round((tp / (tp + fp)) * 100, 2)
f1 = np.round(2 * (pre * sn) / (pre + sn), 2)
print("Accuracy: " + str(acc))
print("Sensitivity/Recall: " + str(sn))
print("Specificity: " + str(sp))
print("MCC: " + str(mcc))
print("Precision: " + str(pre))
print("F1_Score: " + str(f1))

ns_probs6=[0 for _ in range(len(y))]
lr_probs6=clf.predict_proba(X)
# keep probabilities for the positive outcome only
lr_probs6=lr_probs6[:, 1]

# calculate roc curves
ns_fpr6, ns_tpr6, _=roc_curve(y, ns_probs6)
lr_fpr6, lr_tpr6, _=roc_curve(y, lr_probs6)
auc_score6 = round(roc_auc_score(y, lr_probs6),2)

import matplotlib as mpl

from matplotlib import pyplot

#pyplot.figure(figsize=(20, 10), dpi=600)
pyplot.figure(figsize=(8, 6))
# plot the roc curve for the model
pyplot.title("Self Consistency Graph")
pyplot.plot(ns_fpr1, ns_tpr1, linestyle='--')
pyplot.plot(lr_fpr1, lr_tpr1, marker='.', color='green', label='RF AUC :{:.2f}'.format(auc_score))

pyplot.plot(ns_fpr2, ns_tpr2, linestyle='--')
pyplot.plot(lr_fpr2, lr_tpr2, marker='.', color='blue', label='LGBM AUC :{:.2f}'.format(auc_score2))

pyplot.plot(ns_fpr3, ns_tpr3, linestyle='--')
pyplot.plot(lr_fpr3, lr_tpr3, marker='.', color='yellow', label='XGB AUC :{:.2f}'.format(auc_score3))

pyplot.plot(ns_fpr4, ns_tpr4, linestyle='--')
pyplot.plot(lr_fpr4, lr_tpr4, marker='.', color='red', label='ET AUC :{:.2f}'.format(auc_score4))

pyplot.plot(ns_fpr6, ns_tpr6, linestyle='--')
pyplot.plot(lr_fpr6, lr_tpr6, marker='.', color='pink', label='Bagging AUC :{:.2f}'.format(auc_score6))

pyplot.plot(ns_fpr5, ns_tpr5, linestyle='--')
pyplot.plot(lr_fpr5, lr_tpr5, marker='.', color='pink', label='Stacking AUC  :{:.2f}'.format(auc_score5))

# axis labels
#pyplot.xlabel('False Positive Rate')
#pyplot.ylabel('True Positive Rate')
# show the legend
#pyplot.legend(loc="lower right", fontsize=20, ncol=1)
# show the plot
#pyplot.show()


pyplot.plot([0, 1], [0, 1], color='black', lw=1, linestyle='--')
pyplot.xlim([0.0, 1.0])
pyplot.ylim([0.0, 1.05])
pyplot.xlabel('False Positive Rate')
pyplot.ylabel('True Positive Rate')
pyplot.title('Receiver Operating Characteristic (ROC) Curve')
pyplot.legend(loc='lower right')
pyplot.show()

"""# **Independent Test**"""

clf2=LGBMClassifier()
clf1=RandomForestClassifier(n_estimators=100, max_depth=50, oob_score=True, n_jobs=-1, warm_start=True)
clf3 = XGBClassifier(n_estimators=100, max_depth=9, learning_rate=0.1)
clf4=ExtraTreesClassifier(n_estimators=100, max_depth=None, min_samples_split=2)
clf6= BaggingClassifier()

seed = np.random.seed(5)
inputSize=153

from sklearn.metrics import roc_curve
from sklearn.metrics import roc_auc_score
X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.2, random_state=seed)#test_size=0.2
print('Independent Dataset Test Random Forest')
clf=clf1.fit(X_train, Y_train)
pred=np.round(clf.predict(X_test))
tn, fp, fn, tp = confusion_matrix(Y_test, pred, labels=[1, 0]).ravel()
acc = np.round(((tn + tp) / (tn + fp + fn + tp)) * 100, 2)
sp = np.round((tn / (fp + tn)) * 100, 2)
sn = np.round((tp / (tp + fn)) * 100, 2)
mcc = np.round(matthews_corrcoef(Y_test, pred), 5)
pre = np.round((tp / (tp + fp)) * 100, 2)
f1 = np.round(2 * (pre * sn) / (pre + sn), 2)
print("Accuracy: " + str(acc))
print("Sensitivity/Recall: " + str(sn))
print("Specificity: " + str(sp))
print("MCC: " + str(mcc))
print("Precision: " + str(pre))
print("F1_Score: " + str(f1))

ns_probs=[0 for _ in range(len(Y_test))]
lr_probs=clf.predict_proba(X_test)
# keep probabilities for the positive outcome only
lr_probs=lr_probs[:, 1]

# calculate roc curves
ns_fpr1, ns_tpr1, _=roc_curve(Y_test, ns_probs)
lr_fpr1, lr_tpr1, _=roc_curve(Y_test, lr_probs)
auc_score = round(roc_auc_score(Y_test, lr_probs),2)

print('Independent Dataset Test LGBM')
clf=clf2.fit(X_train, Y_train)
pred=np.round(clf.predict(X_test))
tn, fp, fn, tp = confusion_matrix(Y_test, pred, labels=[1, 0]).ravel()
acc = np.round(((tn + tp) / (tn + fp + fn + tp)) * 100, 2)
sp = np.round((tn / (fp + tn)) * 100, 2)
sn = np.round((tp / (tp + fn)) * 100, 2)
mcc = np.round(matthews_corrcoef(Y_test, pred), 5)
pre = np.round((tp / (tp + fp)) * 100, 2)
f1 = np.round(2 * (pre * sn) / (pre + sn), 2)
print("Accuracy: " + str(acc))
print("Sensitivity/Recall: " + str(sn))
print("Specificity: " + str(sp))
print("MCC: " + str(mcc))
print("Precision: " + str(pre))
print("F1_Score: " + str(f1))

ns_probs2=[0 for _ in range(len(Y_test))]
lr_probs2=clf.predict_proba(X_test)
# keep probabilities for the positive outcome only
lr_probs2=lr_probs2[:, 1]

# calculate roc curves
ns_fpr2, ns_tpr2, _=roc_curve(Y_test, ns_probs2)
lr_fpr2, lr_tpr2, _=roc_curve(Y_test, lr_probs2)
auc_score2 = round(roc_auc_score(Y_test, lr_probs2),2)

from sklearn.metrics import roc_curve
from sklearn.metrics import roc_auc_score
X_train, X_test, Y_train, Y_test = train_test_split(X_scaled, y, test_size=0.1, random_state=seed)

print('Independent Dataset Test XGB')
clf=clf3.fit(X_train, Y_train)
pred=np.round(clf.predict(X_test))
tn, fp, fn, tp = confusion_matrix(Y_test, pred, labels=[1, 0]).ravel()
acc = np.round(((tn + tp) / (tn + fp + fn + tp)) * 100, 2)
sp = np.round((tn / (fp + tn)) * 100, 2)
sn = np.round((tp / (tp + fn)) * 100, 2)
mcc = np.round(matthews_corrcoef(Y_test, pred), 5)
pre = np.round((tp / (tp + fp)) * 100, 2)
f1 = np.round(2 * (pre * sn) / (pre + sn), 2)
print("Accuracy: " + str(acc))
print("Sensitivity/Recall: " + str(sn))
print("Specificity: " + str(sp))
print("MCC: " + str(mcc))
print("Precision: " + str(pre))
print("F1_Score: " + str(f1))

ns_probs3=[0 for _ in range(len(Y_test))]
lr_probs3=clf.predict_proba(X_test)
# keep probabilities for the positive outcome only
lr_probs3=lr_probs3[:, 1]

# calculate roc curves
ns_fpr3, ns_tpr3, _=roc_curve(Y_test, ns_probs3)
lr_fpr3, lr_tpr3, _=roc_curve(Y_test, lr_probs3)
auc_score3 = round(roc_auc_score(Y_test, lr_probs3),2)

print('Independent Dataset Test ET')
clf=clf4.fit(X_train, Y_train)
pred=np.round(clf.predict(X_test))
tn, fp, fn, tp = confusion_matrix(Y_test, pred, labels=[1, 0]).ravel()
acc = np.round(((tn + tp) / (tn + fp + fn + tp)) * 100, 2)
sp = np.round((tn / (fp + tn)) * 100, 2)
sn = np.round((tp / (tp + fn)) * 100, 2)
mcc = np.round(matthews_corrcoef(Y_test, pred), 5)
pre = np.round((tp / (tp + fp)) * 100, 2)
f1 = np.round(2 * (pre * sn) / (pre + sn), 2)
print("Accuracy: " + str(acc))
print("Sensitivity/Recall: " + str(sn))
print("Specificity: " + str(sp))
print("MCC: " + str(mcc))
print("Precision: " + str(pre))
print("F1_Score: " + str(f1))

ns_probs4=[0 for _ in range(len(Y_test))]
lr_probs4=clf.predict_proba(X_test)
# keep probabilities for the positive outcome only
lr_probs4=lr_probs4[:, 1]

# calculate roc curves
ns_fpr4, ns_tpr4, _=roc_curve(Y_test, ns_probs4)
lr_fpr4, lr_tpr4, _=roc_curve(Y_test, lr_probs4)
auc_score4 = round(roc_auc_score(Y_test, lr_probs4),2)

print('Independent Dataset Test Bagging')
clf=clf6.fit(X_train, Y_train)
pred=np.round(clf.predict(X_test))
tn, fp, fn, tp = confusion_matrix(Y_test, pred, labels=[1, 0]).ravel()
acc = np.round(((tn + tp) / (tn + fp + fn + tp)) * 100, 2)
sp = np.round((tn / (fp + tn)) * 100, 2)
sn = np.round((tp / (tp + fn)) * 100, 2)
mcc = np.round(matthews_corrcoef(Y_test, pred), 5)
pre = np.round((tp / (tp + fp)) * 100, 2)
f1 = np.round(2 * (pre * sn) / (pre + sn), 2)
print("Accuracy: " + str(acc))
print("Sensitivity/Recall: " + str(sn))
print("Specificity: " + str(sp))
print("MCC: " + str(mcc))
print("Precision: " + str(pre))
print("F1_Score: " + str(f1))

ns_probs6=[0 for _ in range(len(Y_test))]
lr_probs6=clf.predict_proba(X_test)
# keep probabilities for the positive outcome only
lr_probs6=lr_probs6[:, 1]

# calculate roc curves
ns_fpr6, ns_tpr6, _=roc_curve(Y_test, ns_probs6)
lr_fpr6, lr_tpr6, _=roc_curve(Y_test, lr_probs6)
auc_score6 = round(roc_auc_score(Y_test, lr_probs6),2)

lr = LogisticRegression(random_state=42)

# Define your stacking classifier with the base learners and meta-learner
clf5 = StackingClassifier(
    estimators=[('lgbm', clf2),('rf', clf1) ],final_estimator=lr)

print('Independent Dataset Test 5-ENsemble')
clf=clf5.fit(X_train, Y_train)
pred=np.round(clf.predict(X_test))
tn, fp, fn, tp = confusion_matrix(Y_test, pred, labels=[1, 0]).ravel()
acc = np.round(((tn + tp) / (tn + fp + fn + tp)) * 100, 2)
sp = np.round((tn / (fp + tn)) * 100, 2)
sn = np.round((tp / (tp + fn)) * 100, 2)
mcc = np.round(matthews_corrcoef(Y_test, pred), 5)
pre = np.round((tp / (tp + fp)) * 100, 2)
f1 = np.round(2 * (pre * sn) / (pre + sn), 2)
print("Accuracy: " + str(acc))
print("Sensitivity/Recall: " + str(sn))
print("Specificity: " + str(sp))
print("MCC: " + str(mcc))
print("Precision: " + str(pre))
print("F1_Score: " + str(f1))

ns_probs5=[0 for _ in range(len(Y_test))]
lr_probs5=clf.predict_proba(X_test)
# keep probabilities for the positive outcome only
lr_probs5=lr_probs5[:, 1]

# calculate roc curves
ns_fpr5, ns_tpr5, _=roc_curve(Y_test, ns_probs5)
lr_fpr5, lr_tpr5, _=roc_curve(Y_test, lr_probs5)
auc_score5 = round(roc_auc_score(Y_test, lr_probs5),2)

# replace X1 with X_test and Y1 with y_test
from sklearn.metrics import roc_curve, roc_auc_score
from matplotlib import pyplot

#pyplot.rcParams['figure.dpi'] = 200

pyplot.figure(figsize=(20, 10), dpi=600)

# plot the roc curve for the model
#plt.plot(lr_fpr1, lr_tpr1, marker='.', color='green', label=f'RF AUC : {auc_score:.3f}')
#plt.plot(lr_fpr1, lr_tpr1, marker='.', color='green', label='RF AUC : {:.3f}'.format(auc_score))

pyplot.title("Independent Dataset Test Graph")
pyplot.plot(ns_fpr1, ns_tpr1, linestyle='--')
pyplot.plot(lr_fpr1, lr_tpr1, marker='.', color='green', label='RF AUC :{:.2f}'.format(auc_score))

pyplot.plot(ns_fpr2, ns_tpr2, linestyle='--')
pyplot.plot(lr_fpr2, lr_tpr2, marker='.', color='blue', label='LGBM AUC :{:.2f}'.format(auc_score2))

pyplot.plot(ns_fpr3, ns_tpr3, linestyle='--')
pyplot.plot(lr_fpr3, lr_tpr3, marker='.', color='yellow', label='XGB AUC :{:.2f}'.format(auc_score3))

pyplot.plot(ns_fpr4, ns_tpr4, linestyle='--')
pyplot.plot(lr_fpr4, lr_tpr4, marker='.', color='red', label='ET AUC : '+str(auc_score4))

pyplot.plot(ns_fpr6, ns_tpr6, linestyle='--')
pyplot.plot(lr_fpr6, lr_tpr6, marker='.', color='pink', label='Bagging AUC : '+str(auc_score6))

pyplot.plot(ns_fpr5, ns_tpr5, linestyle='--')
pyplot.plot(lr_fpr5, lr_tpr5, marker='.', color='pink', label='Stacking AUC  :{:.2f}'.format(auc_score5))
# axis labels
pyplot.xlabel('False Positive Rate')
pyplot.ylabel('True Positive Rate')
# show the legend
pyplot.legend(loc="lower right", fontsize=22, ncol=1)
# show the plot
pyplot.show()

"""# **10 fold**"""

from sklearn.model_selection import StratifiedKFold, KFold

clf2=LGBMClassifier()
clf1=RandomForestClassifier(n_estimators=50, max_depth=25, oob_score=True, n_jobs=-1, warm_start=True)
clf3 = XGBClassifier(n_estimators=100, max_depth=9, learning_rate=0.1)
clf4=ExtraTreesClassifier()
clf6 = BaggingClassifier(random_state=42)

X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.3, random_state=42)

kfold=StratifiedKFold(n_splits=10, shuffle=True)

print('10-fold Cross-Validation Random Forest')
iterator = 1
for train, test in kfold.split(X, y):
  print("Fold : " + str(iterator))
  X_train = X[train]
  Y_train = y[train]
  X_test = X[test]
  Y_test = y[test]
  clf=clf1.fit(X_train, Y_train)
  pred=np.round(clf.predict(X_test))
  tn, fp, fn, tp = confusion_matrix(Y_test, pred, labels=[1, 0]).ravel()
  acc = np.round(((tn + tp) / (tn + fp + fn + tp)) * 100, 2)
  sp = np.round((tn / (fp + tn)) * 100, 2)
  sn = np.round((tp / (tp + fn)) * 100, 2)
  mcc = np.round(matthews_corrcoef(Y_test, pred), 5)
  pre = np.round((tp / (tp + fp)) * 100, 2)
  f1 = np.round(2 * (pre * sn) / (pre + sn), 2)
  print("Accuracy: " + str(acc))
  print("Sensitivity/Recall: " + str(sn))
  print("Specificity: " + str(sp))
  print("MCC: " + str(mcc))
  print("Precision: " + str(pre))
  print("F1_Score: " + str(f1))
  iterator = iterator+1

kfold=StratifiedKFold(n_splits=10, shuffle=True)

print('10-fold Cross-Validation LGBM')
iterator = 1
for train, test in kfold.split(X, y):
  print("Fold : " + str(iterator))
  X_train = X[train]
  Y_train = y[train]
  X_test = X[test]
  Y_test = y[test]
  clf=clf2.fit(X_train, Y_train)
  pred=np.round(clf.predict(X_test))
  tn, fp, fn, tp = confusion_matrix(Y_test, pred, labels=[1, 0]).ravel()
  acc = np.round(((tn + tp) / (tn + fp + fn + tp)) * 100, 2)
  sp = np.round((tn / (fp + tn)) * 100, 2)
  sn = np.round((tp / (tp + fn)) * 100, 2)
  mcc = np.round(matthews_corrcoef(Y_test, pred), 5)
  pre = np.round((tp / (tp + fp)) * 100, 2)
  f1 = np.round(2 * (pre * sn) / (pre + sn), 2)
  print("Accuracy: " + str(acc))
  print("Sensitivity/Recall: " + str(sn))
  print("Specificity: " + str(sp))
  print("MCC: " + str(mcc))
  print("Precision: " + str(pre))
  print("F1_Score: " + str(f1))
  iterator = iterator+1

kfold=StratifiedKFold(n_splits=10, shuffle=True)

print('10-fold Cross-Validation XGB')
iterator = 1
for train, test in kfold.split(X, y):
  print("Fold : " + str(iterator))
  X_train = X[train]
  Y_train = y[train]
  X_test = X[test]
  Y_test = y[test]
  clf=clf3.fit(X_train, Y_train)
  pred=np.round(clf.predict(X_test))
  tn, fp, fn, tp = confusion_matrix(Y_test, pred, labels=[1, 0]).ravel()
  acc = np.round(((tn + tp) / (tn + fp + fn + tp)) * 100, 2)
  sp = np.round((tn / (fp + tn)) * 100, 2)
  sn = np.round((tp / (tp + fn)) * 100, 2)
  mcc = np.round(matthews_corrcoef(Y_test, pred), 5)
  pre = np.round((tp / (tp + fp)) * 100, 2)
  f1 = np.round(2 * (pre * sn) / (pre + sn), 2)
  print("Accuracy: " + str(acc))
  print("Sensitivity/Recall: " + str(sn))
  print("Specificity: " + str(sp))
  print("MCC: " + str(mcc))
  print("Precision: " + str(pre))
  print("F1_Score: " + str(f1))
  iterator = iterator+1

kfold=StratifiedKFold(n_splits=10, shuffle=True)

print('10-fold Cross-Validation ET')
iterator = 1
for train, test in kfold.split(X, y):
  print("Fold : " + str(iterator))
  X_train = X[train]
  Y_train = y[train]
  X_test = X[test]
  Y_test = y[test]
  clf=clf4.fit(X_train, Y_train)
  pred=np.round(clf.predict(X_test))
  tn, fp, fn, tp = confusion_matrix(Y_test, pred, labels=[1, 0]).ravel()
  acc = np.round(((tn + tp) / (tn + fp + fn + tp)) * 100, 2)
  sp = np.round((tn / (fp + tn)) * 100, 2)
  sn = np.round((tp / (tp + fn)) * 100, 2)
  mcc = np.round(matthews_corrcoef(Y_test, pred), 5)
  pre = np.round((tp / (tp + fp)) * 100, 2)
  f1 = np.round(2 * (pre * sn) / (pre + sn), 2)
  print("Accuracy: " + str(acc))
  print("Sensitivity/Recall: " + str(sn))
  print("Specificity: " + str(sp))
  print("MCC: " + str(mcc))
  print("Precision: " + str(pre))
  print("F1_Score: " + str(f1))
  iterator = iterator+1

kfold=StratifiedKFold(n_splits=10, shuffle=True)

print('10-fold Cross-Validation STacking')
iterator = 1
for train, test in kfold.split(X, y):
  print("Fold : " + str(iterator))
  X_train = X[train]
  Y_train = y[train]
  X_test = X[test]
  Y_test = y[test]
  clf=clf5.fit(X_train, Y_train)
  pred=np.round(clf.predict(X_test))
  tn, fp, fn, tp = confusion_matrix(Y_test, pred, labels=[1, 0]).ravel()
  acc = np.round(((tn + tp) / (tn + fp + fn + tp)) * 100, 2)
  sp = np.round((tn / (fp + tn)) * 100, 2)
  sn = np.round((tp / (tp + fn)) * 100, 2)
  mcc = np.round(matthews_corrcoef(Y_test, pred), 5)
  pre = np.round((tp / (tp + fp)) * 100, 2)
  f1 = np.round(2 * (pre * sn) / (pre + sn), 2)
  print("Accuracy: " + str(acc))
  print("Sensitivity/Recall: " + str(sn))
  print("Specificity: " + str(sp))
  print("MCC: " + str(mcc))
  print("Precision: " + str(pre))
  print("F1_Score: " + str(f1))
  iterator = iterator+1

kfold=StratifiedKFold(n_splits=10, shuffle=True)

print('10-fold Cross-Validation Bagging')
iterator = 1
for train, test in kfold.split(X, y):
  print("Fold : " + str(iterator))
  X_train = X[train]
  Y_train = y[train]
  X_test = X[test]
  Y_test = y[test]
  clf=clf6.fit(X_train, Y_train)
  pred=np.round(clf.predict(X_test))
  tn, fp, fn, tp = confusion_matrix(Y_test, pred, labels=[1, 0]).ravel()
  acc = np.round(((tn + tp) / (tn + fp + fn + tp)) * 100, 2)
  sp = np.round((tn / (fp + tn)) * 100, 2)
  sn = np.round((tp / (tp + fn)) * 100, 2)
  mcc = np.round(matthews_corrcoef(Y_test, pred), 5)
  pre = np.round((tp / (tp + fp)) * 100, 2)
  f1 = np.round(2 * (pre * sn) / (pre + sn), 2)
  print("Accuracy: " + str(acc))
  print("Sensitivity/Recall: " + str(sn))
  print("Specificity: " + str(sp))
  print("MCC: " + str(mcc))
  print("Precision: " + str(pre))
  print("F1_Score: " + str(f1))
  iterator = iterator+1

clf2=LGBMClassifier()
clf1=RandomForestClassifier(n_estimators=50, max_depth=25, oob_score=True, n_jobs=-1, warm_start=True)
clf3 = XGBClassifier(n_estimators=100, max_depth=9, learning_rate=0.1)
clf4=ExtraTreesClassifier()
clf6= BaggingClassifier()

lr = LogisticRegression(random_state=42)

# Define your stacking classifier with the base learners and meta-learner
clf5 = StackingClassifier(
    estimators=[('xgb', clf3),('rf', clf1) ],final_estimator=lr)

cv = 10

from sklearn.model_selection import cross_val_predict
from sklearn.metrics import auc
from sklearn.metrics import roc_curve
from sklearn.metrics import roc_auc_score

lgbm=cross_val_predict(clf2, X_scaled, y, cv=cv,method='predict_proba')
xgb=cross_val_predict(clf3,X_scaled, y, cv=cv,method='predict_proba')
et=cross_val_predict(clf4,X_scaled, y, cv=cv,method='predict_proba')
rf=cross_val_predict(clf1,X_scaled, y, cv=cv,method='predict_proba')
bg=cross_val_predict(clf6,X_scaled, y, cv=cv,method='predict_proba')
st=cross_val_predict(clf5,X_scaled, y, cv=cv,method='predict_proba')

import numpy as np
from sklearn import datasets
from sklearn.model_selection import train_test_split, cross_val_predict
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC
from sklearn.metrics import roc_curve, auc, roc_auc_score
import matplotlib.pyplot as plt

xgb_fpr, xgb_tpr, thresholds = roc_curve(y, xgb[:, 1])
xgb_auc = auc(xgb_fpr, xgb_tpr)


lgbm_fpr, lgbm_tpr, thresholds = roc_curve(y, lgbm[:, 1])
lgbm_auc = auc(lgbm_fpr, lgbm_tpr)

rf_fpr, rf_tpr, thresholds = roc_curve(y, rf[:, 1])
rf_auc = auc(rf_fpr, rf_tpr)

bg_fpr, bg_tpr, thresholds = roc_curve(y, bg[:, 1])
bg_auc = auc(bg_fpr, bg_tpr)

et_fpr, et_tpr, thresholds = roc_curve(y, et[:, 1])
et_auc = auc(et_fpr, et_tpr)

st_fpr, st_tpr, thresholds = roc_curve(y, st[:, 1])
st_auc = auc(st_fpr, st_tpr)




# replace X1 with X_test and Y1 with y_test
from sklearn.metrics import roc_curve, roc_auc_score
import matplotlib.pyplot as plt

plt.figure(figsize=(20, 10), dpi=600)
plt.plot([0, 1], [0, 1], linestyle="--", lw=2,  label="Chance", alpha=0.8)
plt.plot(rf_fpr, rf_tpr, marker='.', label='RF (auc = %0.3f)' % rf_auc)
plt.plot(et_fpr, et_tpr, marker='.', label='ET (auc = %0.3f)' % et_auc)
plt.plot(bg_fpr, bg_tpr, linestyle='-', label='Bagging (auc = %0.3f)' % bg_auc)
plt.plot(st_fpr, st_tpr, linestyle='-', label='Stacking (auc = %0.3f)' % st_auc)
# plt.plot(blfpr, bltpr, linestyle='-', label='Blending (RF,LGBM) (auc = %0.3f)' % bl_auc)
plt.plot(xgb_fpr, xgb_tpr, linestyle='-', label='XGB (auc = %0.3f)' % xgb_auc)
plt.plot(lgbm_fpr, lgbm_tpr, linestyle='-',color='black', label='LGBM (auc = %0.3f)' % lgbm_auc)




# plt.xlabel('False Positive Rate -->')
# plt.ylabel('True Positive Rate -->')

plt.legend(loc="lower right", fontsize=20, ncol=1)

plt.show()

from sklearn.model_selection import cross_val_predict, KFold
from sklearn.ensemble import RandomForestClassifier
from lightgbm import LGBMClassifier
from sklearn.metrics import roc_curve, auc
import numpy as np
import matplotlib.pyplot as plt

# Assuming X and y are already defined with your data

# Initialize classifiers
clf1 = RandomForestClassifier(n_estimators=50, max_depth=25, oob_score=True, n_jobs=-1, warm_start=True, random_state=42)
clf2 = LGBMClassifier(random_state=42)
clf3 = XGBClassifier(n_estimators=100, max_depth=9, learning_rate=0.1, random_state=42)
clf4 = ExtraTreesClassifier(random_state=42)
clf6= BaggingClassifier()

# Define your meta-learner
lr = LogisticRegression(random_state=42)

# Define your stacking classifier with the base learners and meta-learner
clf5 = StackingClassifier(
    estimators=[('xgb', clf3),('rf', clf1) ],final_estimator=lr)

classifiers = {'RF': clf1, 'LGBM': clf2, 'XGB': clf3, 'ET': clf4, 'Stacking': clf5, 'Bagging': clf6}

plt.figure(figsize=(8, 6))

# Perform 5-fold cross-validation for each classifier
for clf_name, clf in classifiers.items():
    mean_fpr = np.linspace(0, 1, 100)
    tprs = []
    aucs = []
    kf = KFold(n_splits=10, shuffle=True, random_state=42)

    for train_index, test_index in kf.split(X):
        X_train, X_test = X[train_index], X[test_index]
        y_train, y_test = y[train_index], y[test_index]

        clf.fit(X_train, y_train)
        y_pred_proba = clf.predict_proba(X_test)[:, 1]

        fpr, tpr, _ = roc_curve(y_test, y_pred_proba)
        tprs.append(np.interp(mean_fpr, fpr, tpr))

    mean_tpr = np.mean(tprs, axis=0)
    mean_tpr[0] = 0.0
    mean_tpr[-1] = 1.0
    mean_auc = auc(mean_fpr, mean_tpr)
    plt.plot(mean_fpr, mean_tpr, label=f'{clf_name} (Mean AUC = {mean_auc:.2f})')

plt.plot([0, 1], [0, 1], color='black', lw=1, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc='lower right')
plt.show()

"""# **Cross Validation 5 Fold**"""

from sklearn.model_selection import cross_val_predict, KFold
from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier
from lightgbm import LGBMClassifier
from xgboost import XGBClassifier
from sklearn.metrics import roc_curve, auc
import numpy as np
import matplotlib.pyplot as plt

# Assuming X and y are already defined with your data

# Initialize classifiers
clf1 = RandomForestClassifier(n_estimators=50, max_depth=25, oob_score=True, n_jobs=-1, warm_start=True, random_state=42)
clf2 = LGBMClassifier(random_state=42)
clf3 = XGBClassifier(n_estimators=100, max_depth=9, learning_rate=0.1, random_state=42)
clf4 = ExtraTreesClassifier(random_state=42)
clf6= BaggingClassifier()

# Define your meta-learner
lr = LogisticRegression(random_state=42)

# Define your stacking classifier with the base learners and meta-learner
clf5 = StackingClassifier(
    estimators=[('xgb', clf3),('rf', clf1) ],final_estimator=lr)

classifiers = {'RF': clf1, 'LGBM': clf2, 'XGB': clf3, 'ET': clf4, 'Stacking': clf5, 'Bagging': clf6}

plt.figure(figsize=(8, 6))

# Perform 5-fold cross-validation for each classifier
for clf_name, clf in classifiers.items():
    mean_fpr = np.linspace(0, 1, 100)
    tprs = []
    aucs = []
    kf = KFold(n_splits=5, shuffle=True, random_state=42)

    for train_index, test_index in kf.split(X):
        X_train, X_test = X[train_index], X[test_index]
        y_train, y_test = y[train_index], y[test_index]

        clf.fit(X_train, y_train)
        y_pred_proba = clf.predict_proba(X_test)[:, 1]

        fpr, tpr, _ = roc_curve(y_test, y_pred_proba)
        tprs.append(np.interp(mean_fpr, fpr, tpr))

    mean_tpr = np.mean(tprs, axis=0)
    mean_tpr[0] = 0.0
    mean_tpr[-1] = 1.0
    mean_auc = auc(mean_fpr, mean_tpr)
    plt.plot(mean_fpr, mean_tpr, label=f'{clf_name} (Mean AUC = {mean_auc:.2f})')

plt.plot([0, 1], [0, 1], color='black', lw=1, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc='lower right')
plt.show()

clf2=LGBMClassifier()
clf1=RandomForestClassifier(n_estimators=50, max_depth=25, oob_score=True, n_jobs=-1, warm_start=True)
clf3 = XGBClassifier(n_estimators=100, max_depth=9, learning_rate=0.1)
clf4=ExtraTreesClassifier()
clf6 = BaggingClassifier(random_state=42)

lr = LogisticRegression(random_state=42)

# Define your stacking classifier with the base learners and meta-learner
clf5 = StackingClassifier(
    estimators=[('xgb', clf3),('et', clf4),('lgbm', clf2),('rf', clf1) ],final_estimator=lr)

X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.2, random_state=42)

from sklearn.model_selection import StratifiedKFold, KFold

kfold=StratifiedKFold(n_splits=5, shuffle=True)

print('5-fold Cross-Validation Random Forest')
iterator = 1
for train, test in kfold.split(X, y):
  print("Fold : " + str(iterator))
  X_train = X[train]
  Y_train = y[train]
  X_test = X[test]
  Y_test = y[test]
  clf=clf1.fit(X_train, Y_train)
  pred=np.round(clf.predict(X_test))
  tn, fp, fn, tp = confusion_matrix(Y_test, pred, labels=[1, 0]).ravel()
  acc = np.round(((tn + tp) / (tn + fp + fn + tp)) * 100, 2)
  sp = np.round((tn / (fp + tn)) * 100, 2)
  sn = np.round((tp / (tp + fn)) * 100, 2)
  mcc = np.round(matthews_corrcoef(Y_test, pred), 5)
  pre = np.round((tp / (tp + fp)) * 100, 2)
  f1 = np.round(2 * (pre * sn) / (pre + sn), 2)
  print("Accuracy: " + str(acc))
  print("Sensitivity/Recall: " + str(sn))
  print("Specificity: " + str(sp))
  print("MCC: " + str(mcc))
  print("Precision: " + str(pre))
  print("F1_Score: " + str(f1))
  iterator = iterator+1

kfold=StratifiedKFold(n_splits=5, shuffle=True)

print('5-fold Cross-Validation LGBM')
iterator = 1
for train, test in kfold.split(X, y):
  print("Fold : " + str(iterator))
  X_train = X[train]
  Y_train = y[train]
  X_test = X[test]
  Y_test = y[test]
  clf=clf2.fit(X_train, Y_train)
  pred=np.round(clf.predict(X_test))
  tn, fp, fn, tp = confusion_matrix(Y_test, pred, labels=[1, 0]).ravel()
  acc = np.round(((tn + tp) / (tn + fp + fn + tp)) * 100, 2)
  sp = np.round((tn / (fp + tn)) * 100, 2)
  sn = np.round((tp / (tp + fn)) * 100, 2)
  mcc = np.round(matthews_corrcoef(Y_test, pred), 5)
  pre = np.round((tp / (tp + fp)) * 100, 2)
  f1 = np.round(2 * (pre * sn) / (pre + sn), 2)
  print("Accuracy: " + str(acc))
  print("Sensitivity/Recall: " + str(sn))
  print("Specificity: " + str(sp))
  print("MCC: " + str(mcc))
  print("Precision: " + str(pre))
  print("F1_Score: " + str(f1))
  iterator = iterator+1

kfold=StratifiedKFold(n_splits=5, shuffle=True)

print('5-fold Cross-Validation XGB')
iterator = 1
for train, test in kfold.split(X, y):
  print("Fold : " + str(iterator))
  X_train = X[train]
  Y_train = y[train]
  X_test = X[test]
  Y_test = y[test]
  clf=clf3.fit(X_train, Y_train)
  pred=np.round(clf.predict(X_test))
  tn, fp, fn, tp = confusion_matrix(Y_test, pred, labels=[1, 0]).ravel()
  acc = np.round(((tn + tp) / (tn + fp + fn + tp)) * 100, 2)
  sp = np.round((tn / (fp + tn)) * 100, 2)
  sn = np.round((tp / (tp + fn)) * 100, 2)
  mcc = np.round(matthews_corrcoef(Y_test, pred), 5)
  pre = np.round((tp / (tp + fp)) * 100, 2)
  f1 = np.round(2 * (pre * sn) / (pre + sn), 2)
  print("Accuracy: " + str(acc))
  print("Sensitivity/Recall: " + str(sn))
  print("Specificity: " + str(sp))
  print("MCC: " + str(mcc))
  print("Precision: " + str(pre))
  print("F1_Score: " + str(f1))
  iterator = iterator+1

kfold=StratifiedKFold(n_splits=5, shuffle=True)

print('5-fold Cross-Validation ExtraTree')
iterator = 1
for train, test in kfold.split(X, y):
  print("Fold : " + str(iterator))
  X_train = X[train]
  Y_train = y[train]
  X_test = X[test]
  Y_test = y[test]
  clf=clf4.fit(X_train, Y_train)
  pred=np.round(clf.predict(X_test))
  tn, fp, fn, tp = confusion_matrix(Y_test, pred, labels=[1, 0]).ravel()
  acc = np.round(((tn + tp) / (tn + fp + fn + tp)) * 100, 2)
  sp = np.round((tn / (fp + tn)) * 100, 2)
  sn = np.round((tp / (tp + fn)) * 100, 2)
  mcc = np.round(matthews_corrcoef(Y_test, pred), 5)
  pre = np.round((tp / (tp + fp)) * 100, 2)
  f1 = np.round(2 * (pre * sn) / (pre + sn), 2)
  print("Accuracy: " + str(acc))
  print("Sensitivity/Recall: " + str(sn))
  print("Specificity: " + str(sp))
  print("MCC: " + str(mcc))
  print("Precision: " + str(pre))
  print("F1_Score: " + str(f1))
  iterator = iterator+1

kfold=StratifiedKFold(n_splits=5, shuffle=True)

print('5-fold Cross-Validation Bagging')
iterator = 1
for train, test in kfold.split(X, y):
  print("Fold : " + str(iterator))
  X_train = X[train]
  Y_train = y[train]
  X_test = X[test]
  Y_test = y[test]
  clf=clf6.fit(X_train, Y_train)
  pred=np.round(clf.predict(X_test))
  tn, fp, fn, tp = confusion_matrix(Y_test, pred, labels=[1, 0]).ravel()
  acc = np.round(((tn + tp) / (tn + fp + fn + tp)) * 100, 2)
  sp = np.round((tn / (fp + tn)) * 100, 2)
  sn = np.round((tp / (tp + fn)) * 100, 2)
  mcc = np.round(matthews_corrcoef(Y_test, pred), 5)
  pre = np.round((tp / (tp + fp)) * 100, 2)
  f1 = np.round(2 * (pre * sn) / (pre + sn), 2)
  print("Accuracy: " + str(acc))
  print("Sensitivity/Recall: " + str(sn))
  print("Specificity: " + str(sp))
  print("MCC: " + str(mcc))
  print("Precision: " + str(pre))
  print("F1_Score: " + str(f1))
  iterator = iterator+1

kfold=StratifiedKFold(n_splits=5, shuffle=True)

print('5-fold Cross-Validation Stacking')
iterator = 1
for train, test in kfold.split(X, y):
  print("Fold : " + str(iterator))
  X_train = X[train]
  Y_train = y[train]
  X_test = X[test]
  Y_test = y[test]
  clf=clf5.fit(X_train, Y_train)
  pred=np.round(clf.predict(X_test))
  tn, fp, fn, tp = confusion_matrix(Y_test, pred, labels=[1, 0]).ravel()
  acc = np.round(((tn + tp) / (tn + fp + fn + tp)) * 100, 2)
  sp = np.round((tn / (fp + tn)) * 100, 2)
  sn = np.round((tp / (tp + fn)) * 100, 2)
  mcc = np.round(matthews_corrcoef(Y_test, pred), 5)
  pre = np.round((tp / (tp + fp)) * 100, 2)
  f1 = np.round(2 * (pre * sn) / (pre + sn), 2)
  print("Accuracy: " + str(acc))
  print("Sensitivity/Recall: " + str(sn))
  print("Specificity: " + str(sp))
  print("MCC: " + str(mcc))
  print("Precision: " + str(pre))
  print("F1_Score: " + str(f1))
  iterator = iterator+1

"""# **Lazy Predict**"""

pip install lazypredict

import pandas as pd
from sklearn.model_selection import train_test_split
from lazypredict.Supervised import LazyClassifier
from sklearn.datasets import load_iris



# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize LazyClassifier
clf = LazyClassifier(verbose=0, ignore_warnings=True, custom_metric=None)

# Fit the classifier on the training data
models, predictions = clf.fit(X_train, X_test, y_train, y_test)

# Display the performance metrics
print(models)

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from lazypredict.Supervised import LazyClassifier
from sklearn.datasets import load_iris
from sklearn.metrics import accuracy_score, precision_score, confusion_matrix



# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize LazyClassifier
clf = LazyClassifier(verbose=0, ignore_warnings=True, custom_metric=None)

# Fit the classifier on the training data
models, predictions = clf.fit(X_train, X_test, y_train, y_test)

# Display the performance metrics from LazyPredict
print(models)

# Choose the best classifier based on accuracy (first one in the list)
best_model_name = models.index[0]
best_model = clf.models[best_model_name]

# Predict on the test set using the best model
y_pred = best_model.predict(X_test)

# Calculate accuracy
accuracy = accuracy_score(y_test, y_pred)

# Calculate precision
precision = precision_score(y_test, y_pred, average='weighted')

# Calculate specificity
# Specificity is calculated for each class, here we'll take the mean specificity
conf_matrix = confusion_matrix(y_test, y_pred)
tn = conf_matrix[0, 0]
fp = conf_matrix[0, 1]
fn = conf_matrix[1, 0]
tp = conf_matrix[1, 1]

specificity = tn / (tn + fp)

# Print metrics
print(f'Accuracy: {accuracy:.4f}')
print(f'Precision: {precision:.4f}')
print(f'Specificity: {specificity:.4f}')

# Note: Specificity calculation is more meaningful for binary classification.
# For multi-class classification, you'd typically calculate specificity for each class.

"""# **TSNE & Boundry----Graph**"""

pca_50 = PCA(n_components=50)
pca_result_50 = pca_50.fit_transform(X_scaled)
print('Cumulative explained variation for 50 principal components: {}'.format(np.sum(pca_50.explained_variance_ratio_)))

pca_result_50

time_start = time.time()
tsne = TSNE(n_components=2, verbose=0, perplexity=50, n_iter=300)
tsne_pca_results = tsne.fit_transform(pca_result_50)
print('t-SNE done! Time elapsed: {} seconds'.format(time.time()-time_start))

# visualise again and highlight actual classes of data

target_ids = range(len(y))

plt.figure(figsize=(10, 8))
colours = ['purple','orange' ]
label = ['VTP','NON-VTP' ]
for i, c, label in zip(target_ids, colours, label):
    plt.scatter(tsne_pca_results[y == i, 0], tsne_pca_results[y == i, 1], c=c, label=label, alpha=0.3, linewidths = 2 )
    pass

plt.legend()
plt.show()

import numpy as np
import matplotlib.pyplot as plt
from matplotlib.colors import ListedColormap
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.datasets import make_moons, make_circles, make_classification
from sklearn.neural_network import MLPClassifier
from sklearn.neighbors import KNeighborsClassifier
from lightgbm import LGBMClassifier
from sklearn.ensemble import BaggingClassifier, ExtraTreesClassifier
from sklearn.svm import SVC
from sklearn.gaussian_process import GaussianProcessClassifier
from sklearn.gaussian_process.kernels import RBF
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis
import xgboost as xgb
from xgboost import XGBClassifier

h=0.2
names = [
    "Random Forest",
    "LGBM",
    "XGB",
    "ET",
    "Bagging",
    "Stacking"
]
from sklearn.linear_model import LogisticRegression

lr = LogisticRegression(random_state=42)

# Define your stacking classifier with the base learners and meta-learner
clf5 = StackingClassifier(
    estimators=[('xgb', clf3),('rf', clf1) ],final_estimator=lr)

classifiers = [
    RandomForestClassifier(n_estimators=50, max_depth=25, oob_score=True, n_jobs=-1, warm_start=True),
   LGBMClassifier(),
    XGBClassifier(n_estimators=100, max_depth=9, learning_rate=0.1),
    ExtraTreesClassifier(),
     BaggingClassifier(),
    clf5
]

X, y =  tsne_pca_results,y
rng = np.random.RandomState(2)
X += 2 * rng.uniform(size=X.shape)
linearly_separable = (X, y)

datasets = [
    make_moons(noise=0.3, random_state=0),
    make_circles(noise=0.2, factor=0.5, random_state=1),
    linearly_separable,
]

figure = plt.figure(figsize=(27, 9))
i = 1
# iterate over datasets
for ds_cnt, ds in enumerate(datasets):
    # preprocess dataset, split into training and test part
    X, y = ds
    X = StandardScaler().fit_transform(X)
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.4, random_state=42
    )

    x_min, x_max = X[:, 0].min() - 0.5, X[:, 0].max() + 0.5
    y_min, y_max = X[:, 1].min() - 0.5, X[:, 1].max() + 0.5
    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))

    # just plot the dataset first
    cm = plt.cm.RdBu
    cm_bright = ListedColormap(["#FF0000", "#0000FF"])
    ax = plt.subplot(len(datasets), len(classifiers) + 1, i)
    if ds_cnt == 0:
        ax.set_title("Input data")
    # Plot the training points
    ax.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright, edgecolors="k")

    ax.set_xlim(xx.min(), xx.max())
    ax.set_ylim(yy.min(), yy.max())
    ax.set_xticks(())
    ax.set_yticks(())
    i += 1

    # iterate over classifiers
    for name, clf in zip(names, classifiers):
        ax = plt.subplot(len(datasets), len(classifiers) + 1, i)
        clf.fit(X_train, y_train)
        score = clf.score(X_test, y_test)

        # Plot the decision boundary. For that, we will assign a color to each
        # point in the mesh [x_min, x_max]x[y_min, y_max].
        if hasattr(clf, "decision_function"):
            Z = clf.decision_function(np.c_[xx.ravel(), yy.ravel()])
        else:
            Z = clf.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]

        # Put the result into a color plot
        Z = Z.reshape(xx.shape)
        ax.contourf(xx, yy, Z, cmap=cm, alpha=0.8)
# Plot the training points
        ax.scatter(
            X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright, edgecolors="k"
        )

         # Plot the testing points
        ax.scatter(
            X_test[:, 0],
            X_test[:, 1],
            c=y_test,
            cmap=cm_bright,
            edgecolors="k",
            alpha=0.6,
        )
        ax.set_xlim(xx.min(), xx.max())
        ax.set_ylim(yy.min(), yy.max())
        ax.set_xticks(())
        ax.set_yticks(())
        if ds_cnt == 0:
            ax.set_title(name)
        ax.text(
            xx.max() - 0.3,
            yy.min() + 0.3,
            ("%.2f" % score).lstrip("0"),
            size=15,
            horizontalalignment="right",
        )
        i += 1
plt.figure(figsize=(20, 20), dpi=600)

plt.tight_layout()
plt.show()

from sklearn.model_selection import cross_val_score
from sklearn.ensemble import RandomForestClassifier
import numpy as np

# Assuming X_scaled and y are your preprocessed features and target variable
rf = RandomForestClassifier(n_estimators=50, max_depth=25, oob_score=True, n_jobs=-1, warm_start=True, random_state=42)
cv_scores = cross_val_score(rf, X_scaled, y, cv=5)

# Print the scores for each fold
print("Cross-validation scores for each fold:", cv_scores)

# Print the mean and standard deviation of the scores
mean_cv_score = np.mean(cv_scores)
std_cv_score = np.std(cv_scores)
print(f"Mean accuracy: {mean_cv_score:.4f}")
print(f"Standard deviation: {std_cv_score:.4f}")

# Check if the mean and std align with expected values
expected_mean = 0.9403
expected_std = 0.0096

print(f"Expected Mean: {expected_mean:.4f}, Expected Standard Deviation: {expected_std:.4f}")

from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import cross_val_score
import numpy as np

# Example preprocessing steps
# Replace this with your actual preprocessing steps
def preprocess_data():
    # Example data, replace with your actual data
    X = np.random.rand(1000, 20)  # Replace with actual features
    y = np.random.randint(0, 2, 1000)  # Replace with actual labels
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)
    return X_scaled, y

# Preprocess data
X_scaled, y = preprocess_data()

# Initialize model
rf = RandomForestClassifier(n_estimators=50, max_depth=25, oob_score=True, n_jobs=-1, warm_start=True, random_state=42)

# Perform cross-validation
cv_scores = cross_val_score(rf, X_scaled, y, cv=5)

# Print the scores for each fold
print("Cross-validation scores for each fold:", cv_scores)

# Print the mean and standard deviation of the scores
mean_cv_score = np.mean(cv_scores)
std_cv_score = np.std(cv_scores)
print(f"Mean accuracy: {mean_cv_score:.4f}")
print(f"Standard deviation: {std_cv_score:.4f}")

# Expected values
expected_mean = 0.9403
expected_std = 0.0096
print(f"Expected Mean: {expected_mean:.4f}, Expected Standard Deviation: {expected_std:.4f}")

from sklearn.model_selection import cross_val_score
cv=5

et=cross_val_score(ExtraTreesClassifier(), X_scaled, y, cv=cv)

et

rf=cross_val_score(RandomForestClassifier(n_estimators=50, max_depth=25, oob_score=True, n_jobs=-1, warm_start=True, random_state=42),X_scaled, y, cv=cv)

rf

xgb=cross_val_score(XGBClassifier(n_estimators=100, max_depth=9, learning_rate=0.1),X_scaled, y, cv=cv)

xgb

bg=cross_val_score(BaggingClassifier(), X_scaled, y, cv=cv)

bg

lgbm=cross_val_score(LGBMClassifier(), X_scaled, y, cv=cv)

lgbm

lr=cross_val_score(LogisticRegression(), X_scaled, y, cv=cv)

lr

# Define your meta-learner
clf1=RandomForestClassifier(n_estimators=50, max_depth=25, oob_score=True, n_jobs=-1, warm_start=True, random_state=42)
clf2=LogisticRegression()
clf3 = XGBClassifier(n_estimators=100, max_depth=9, learning_rate=0.1)
clf4=ExtraTreesClassifier()
clf6= BaggingClassifier()
lr = LogisticRegression(random_state=42)
clf5 = StackingClassifier(
    estimators=[('xgb', clf3),('rf', clf1) ],final_estimator=lr)

st=cross_val_score(clf5, X_scaled, y, cv=cv)

# Key Changes for Colored Violins and Legend
unique_algos = v10['algo'].unique()
palette = seaborn.color_palette("husl", len(unique_algos))  # Choose a color palette

for i, algo in enumerate(unique_algos):
    algo_data = v10[v10['algo'] == algo]  # Filter data for this algorithm
    seaborn.violinplot(
        ax=ax,
        y=algo_data["Accuracy"],
        x=algo_data["folds"],
        color=palette[i],  # Assign a unique color
    )

"""Word Cloud"""

# Train a Random Forest classifier
clf = RandomForestClassifier(n_estimators=100, random_state=42)
clf.fit(X_train, y_train)

# Plot decision boundary (Random Forest doesn't have a clear decision boundary like SVC)
def plot_decision_boundary(clf, X, y):
    # No decision boundary to plot for Random Forest
    # Plot data points
    plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.Paired, edgecolors='k')
    plt.xlabel('Feature 1')
    plt.ylabel('Feature 2')
    plt.title('Data Points')
    plt.show()

plot_decision_boundary(clf, X_test, y_test)

seed = np.random.seed(5)
inputSize=153
dataset = pd.read_csv('/content/drive/MyDrive/vesicularnew.csv', sep=',', header=None)
#dataset=pd.read_csv('/content/drive/MyDrive/alz-balance-FV.csv', sep=',',header=None)
dataset = dataset.replace([np.inf, -np.inf], np.nan)
dataset = dataset.fillna(0)

for col in dataset.columns:
    dataset[col].where(dataset[col].notnull(), 0, inplace=True)

import pandas as pd

def replace_text_in_dataframe(text, replacement, dataframe):
    return dataframe.applymap(lambda x: replacement if str(x) == text else x)

search_text = '#NAME?'
replacement = 0
df_replaced = replace_text_in_dataframe(search_text, replacement, dataset)

import pandas as pd

# Assuming df is your DataFrame
df_replaced.columns = ['col' + str(i) for i in range(1, 155)]

# Now your columns will be named col1, col2, ..., col522
df_replaced.head()  # Display the first few rows to verify the changes
df_replaced=df_replaced.drop(0)
df_replaced

X1 = df_replaced.iloc[:, : inputSize]
Y1 = df_replaced.iloc[:, inputSize: inputSize+1]
# dataset
X1 = X1.to_numpy()
Y1 = Y1.to_numpy()

from sklearn.preprocessing import StandardScaler, MinMaxScaler
import numpy as np

std_scale = MinMaxScaler()
X1 = np.nan_to_num(X1.astype('float32'))
X1 = std_scale.fit_transform(X1)

df_replaced

dataset

# train=pd.read_csv('trainHYBRID.csv')
# test=pd.read_csv('testHYBRID.csv')
# y_train=train['class']
# X_train=train.drop(['Unnamed: 0','class'],axis=1)
# y_test=test['class']
# X_test=test.drop(['Unnamed: 0','class'],axis=1)

X = X1

X

len(X)

y = Y1
y

len(y)

pca_50 = PCA(n_components=50)
pca_result_50 = pca_50.fit_transform(X)
print('Cumulative explained variation for 50 principal components: {}'.format(np.sum(pca_50.explained_variance_ratio_)))

pca_result_50

time_start = time.time()
tsne = TSNE(n_components=2, verbose=0, perplexity=50, n_iter=300)
tsne_pca_results = tsne.fit_transform(pca_result_50)
print('t-SNE done! Time elapsed: {} seconds'.format(time.time()-time_start))

import matplotlib.pyplot as plt
import numpy as np

# Assuming tsne_pca_results is a 2D array with shape (n_samples, 2)
# and y is a 1D array with shape (n_samples,)
# Replace the following lines with your actual data
n_samples = 1000
tsne_pca_results = np.random.rand(n_samples, 2)
y = np.random.randint(0, 2, size=n_samples)

target_ids = range(len(np.unique(y)))

plt.figure(figsize=(10, 8))
colours = ['purple', 'orange']
labels = ['TE', 'NON-TE']

for i, c, label in zip(target_ids, colours, labels):
    plt.scatter(tsne_pca_results[y == i, 0], tsne_pca_results[y == i, 1], c=c, label=label, alpha=0.3, linewidths=2)

plt.legend()
plt.title('t-SNE visualization of the dataset')
plt.xlabel('t-SNE component 1')
plt.ylabel('t-SNE component 2')
plt.show()

print(len(tsne_pca_results))
print(len(y))

# visualise again and highlight actual classes of data

target_ids = range(len(y))

plt.figure(figsize=(10, 8))
colours = ['purple','orange','g','yellow','red','black','m','r','y','teal','pink','green','y']
label = ['Copia','Gypsy','Pao','Line','L1','Sine','Harbinger','hAt','Mutator','Tc-Marnier','Cacta','Mite','Heli']
for i, c, label in zip(target_ids, colours, label):
    plt.scatter(tsne_pca_results[y == i, 0], tsne_pca_results[y == i, 1], c=c, label=label, alpha=0.3, linewidths = 2 )
    pass

plt.legend()
plt.show()

import numpy as np
import matplotlib.pyplot as plt
from matplotlib.colors import ListedColormap
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.datasets import make_moons, make_circles, make_classification
from sklearn.neural_network import MLPClassifier
from sklearn.neighbors import KNeighborsClassifier
from lightgbm import LGBMClassifier
from sklearn.ensemble import BaggingClassifier, ExtraTreesClassifier
from sklearn.svm import SVC
from sklearn.gaussian_process import GaussianProcessClassifier
from sklearn.gaussian_process.kernels import RBF
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis
import xgboost as xgb
from xgboost import XGBClassifier

h=0.2
names = [
    "Random Forest",
    "Bagging",
    "ET",
    "XGB",
    "LR",
]
from sklearn.linear_model import LogisticRegression

classifiers = [
    RandomForestClassifier(n_estimators=50, max_depth=25, oob_score=True, n_jobs=-1, warm_start=True),
    BaggingClassifier(),
    ExtraTreesClassifier(),
    XGBClassifier(n_estimators=100, max_depth=9, learning_rate=0.1),
LogisticRegression()
]

X, y =  tsne_pca_results,y
rng = np.random.RandomState(2)
X += 2 * rng.uniform(size=X.shape)
linearly_separable = (X, y)

datasets = [
    make_moons(noise=0.3, random_state=0),
    make_circles(noise=0.2, factor=0.5, random_state=1),
    linearly_separable,
]

figure = plt.figure(figsize=(27, 9))
i = 1
# iterate over datasets
for ds_cnt, ds in enumerate(datasets):
    # preprocess dataset, split into training and test part
    X, y = ds
    X = StandardScaler().fit_transform(X)
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.4, random_state=42
    )

    x_min, x_max = X[:, 0].min() - 0.5, X[:, 0].max() + 0.5
    y_min, y_max = X[:, 1].min() - 0.5, X[:, 1].max() + 0.5
    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))

    # just plot the dataset first
    cm = plt.cm.RdBu
    cm_bright = ListedColormap(["#FF0000", "#0000FF"])
    ax = plt.subplot(len(datasets), len(classifiers) + 1, i)
    if ds_cnt == 0:
        ax.set_title("Input data")
    # Plot the training points
    ax.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright, edgecolors="k")

    ax.set_xlim(xx.min(), xx.max())
    ax.set_ylim(yy.min(), yy.max())
    ax.set_xticks(())
    ax.set_yticks(())
    i += 1

    # iterate over classifiers
    for name, clf in zip(names, classifiers):
        ax = plt.subplot(len(datasets), len(classifiers) + 1, i)
        clf.fit(X_train, y_train)
        score = clf.score(X_test, y_test)

        # Plot the decision boundary. For that, we will assign a color to each
        # point in the mesh [x_min, x_max]x[y_min, y_max].
        if hasattr(clf, "decision_function"):
            Z = clf.decision_function(np.c_[xx.ravel(), yy.ravel()])
        else:
            Z = clf.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]

        # Put the result into a color plot
        Z = Z.reshape(xx.shape)
        ax.contourf(xx, yy, Z, cmap=cm, alpha=0.8)
# Plot the training points
        ax.scatter(
            X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright, edgecolors="k"
        )

         # Plot the testing points
        ax.scatter(
            X_test[:, 0],
            X_test[:, 1],
            c=y_test,
            cmap=cm_bright,
            edgecolors="k",
            alpha=0.6,
        )
        ax.set_xlim(xx.min(), xx.max())
        ax.set_ylim(yy.min(), yy.max())
        ax.set_xticks(())
        ax.set_yticks(())
        if ds_cnt == 0:
            ax.set_title(name)
        ax.text(
            xx.max() - 0.3,
            yy.min() + 0.3,
            ("%.2f" % score).lstrip("0"),
            size=15,
            horizontalalignment="right",
        )
        i += 1
plt.figure(figsize=(20, 20), dpi=600)

plt.tight_layout()
plt.show()

import numpy as np
import matplotlib.pyplot as plt
from matplotlib.colors import ListedColormap
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.datasets import make_moons, make_circles, make_classification
from sklearn.neural_network import MLPClassifier
from sklearn.neighbors import KNeighborsClassifier
from lightgbm import LGBMClassifier
from sklearn.ensemble import ExtraTreesClassifier
from sklearn.svm import SVC
from sklearn.ensemble import StackingClassifier
from sklearn.gaussian_process import GaussianProcessClassifier
from sklearn.gaussian_process.kernels import RBF
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier
from sklearn.svm import LinearSVC
from sklearn.naive_bayes import GaussianNB
from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis
import xgboost as xgb
from xgboost import XGBClassifier

h=0.2
xgbst=XGBClassifier(n_estimators=100, max_depth=9, learning_rate=0.1)
etst=ExtraTreesClassifier()
rfst=RandomForestClassifier(n_estimators=50, max_depth=25, oob_score=True, n_jobs=-1, warm_start=True)
bg=BaggingClassifier()
lsvc=LinearSVC()

# Define your meta-learner
lr = LogisticRegression(random_state=42)

# Define your stacking classifier with the base learners and meta-learner

str = StackingClassifier(
    estimators=[('xgb', xgbst),('et', etst),('LSVC', lsvc),('rf', rfst) ],final_estimator=lr)


names = [
    "Random Forest",
    "ET",
    "Bagging",
    "XGB",
    "LR",
    "Stacking",
]
from sklearn.linear_model import LogisticRegression

classifiers = [
    RandomForestClassifier(n_estimators=50, max_depth=25, oob_score=True, n_jobs=-1, warm_start=True),
    ExtraTreesClassifier(),
    BaggingClassifier(),
    XGBClassifier(n_estimators=100, max_depth=9, learning_rate=0.1) ,
    LogisticRegression(random_state=42),
    st
]

X, y =  tsne_pca_results,y
rng = np.random.RandomState(2)
X += 2 * rng.uniform(size=X.shape)
linearly_separable = (X, y)

datasets = [
    make_moons(noise=0.3, random_state=0),
    make_circles(noise=0.2, factor=0.5, random_state=1),
    linearly_separable,
]

figure = plt.figure(figsize=(27, 9))
i = 1
# iterate over datasets
for ds_cnt, ds in enumerate(datasets):
    # preprocess dataset, split into training and test part
    X, y = ds
    X = StandardScaler().fit_transform(X)
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.4, random_state=42
    )

    x_min, x_max = X[:, 0].min() - 0.5, X[:, 0].max() + 0.5
    y_min, y_max = X[:, 1].min() - 0.5, X[:, 1].max() + 0.5
    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))

    # just plot the dataset first
    cm = plt.cm.RdBu
    cm_bright = ListedColormap(["#FF0000", "#0000FF"])
    ax = plt.subplot(len(datasets), len(classifiers) + 1, i)
    if ds_cnt == 0:
        ax.set_title("Input data")
    # Plot the training points
    ax.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright, edgecolors="k")

    ax.set_xlim(xx.min(), xx.max())
    ax.set_ylim(yy.min(), yy.max())
    ax.set_xticks(())
    ax.set_yticks(())
    i += 1

    # iterate over classifiers
    for name, clf in zip(names, classifiers):
        ax = plt.subplot(len(datasets), len(classifiers) + 1, i)
        clf.fit(X_train, y_train)
        score = clf.score(X_test, y_test)

        # Plot the decision boundary. For that, we will assign a color to each
        # point in the mesh [x_min, x_max]x[y_min, y_max].
        if hasattr(clf, "decision_function"):
            Z = clf.decision_function(np.c_[xx.ravel(), yy.ravel()])
        else:
            Z = clf.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]

        # Put the result into a color plot
        Z = Z.reshape(xx.shape)
        ax.contourf(xx, yy, Z, cmap=cm, alpha=0.8)
# Plot the training points
        ax.scatter(
            X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright, edgecolors="k"
        )

         # Plot the testing points
        ax.scatter(
            X_test[:, 0],
            X_test[:, 1],
            c=y_test,
            cmap=cm_bright,
            edgecolors="k",
            alpha=0.6,
        )
        ax.set_xlim(xx.min(), xx.max())
        ax.set_ylim(yy.min(), yy.max())
        ax.set_xticks(())
        ax.set_yticks(())
        if ds_cnt == 0:
            ax.set_title(name)
        ax.text(
            xx.max() - 0.3,
            yy.min() + 0.3,
            ("%.2f" % score).lstrip("0"),
            size=15,
            horizontalalignment="right",
        )
        i += 1
plt.figure(figsize=(20, 20), dpi=600)

plt.tight_layout()
plt.show()

# Correction
import numpy as np
import matplotlib.pyplot as plt
from matplotlib.colors import ListedColormap
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.datasets import make_moons, make_circles
from sklearn.ensemble import BaggingClassifier
from sklearn.linear_model import LogisticRegression
import xgboost as xgb
from xgboost import XGBClassifier
from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier, StackingClassifier
from sklearn.svm import LinearSVC

# Parameters for visualization
h = 0.2  # Step size in the mesh

# Define classifiers
xgbst = XGBClassifier(n_estimators=100, max_depth=9, learning_rate=0.1)
etst = ExtraTreesClassifier()
rfst = RandomForestClassifier(n_estimators=50, max_depth=25, oob_score=True, n_jobs=-1, warm_start=True)
bg = BaggingClassifier()
lsvc = LinearSVC()

# Define meta-learner
lr = LogisticRegression(random_state=42)

# Define stacking classifier
str_clf = StackingClassifier(
    estimators=[('xgb', xgbst), ('et', etst), ('LSVC', lsvc), ('rf', rfst)],
    final_estimator=lr
)

# Names of the classifiers
names = [
    "Random Forest",
    "ET",
    "Bagging",
    "XGB",
    "LR",
    "Stacking"
]

classifiers = [
    rfst,
    etst,
    bg,
    xgbst,
    LogisticRegression(random_state=42),
    str_clf
]

# Generate some example data
X, y = np.random.rand(100, 2), np.random.randint(0, 2, 100)

# Randomly generate additional datasets
datasets = [
    make_moons(noise=0.3, random_state=0),
    make_circles(noise=0.2, factor=0.5, random_state=1),
    (X, y)
]

# Create the figure
figure = plt.figure(figsize=(27, 9))
i = 1

# Iterate over datasets
for ds_cnt, ds in enumerate(datasets):
    # Preprocess dataset, split into training and test parts
    X, y = ds
    X = StandardScaler().fit_transform(X)
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)

    x_min, x_max = X[:, 0].min() - 0.5, X[:, 0].max() + 0.5
    y_min, y_max = X[:, 1].min() - 0.5, X[:, 1].max() + 0.5
    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))

    # Plot the dataset
    cm = plt.cm.RdBu
    cm_bright = ListedColormap(["#FF0000", "#0000FF"])
    ax = plt.subplot(len(datasets), len(classifiers) + 1, i)
    if ds_cnt == 0:
        ax.set_title("Input data")
    ax.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright, edgecolors="k")
    ax.set_xlim(xx.min(), xx.max())
    ax.set_ylim(yy.min(), yy.max())
    ax.set_xticks(())
    ax.set_yticks(())
    i += 1

    # Iterate over classifiers
    for name, clf in zip(names, classifiers):
        ax = plt.subplot(len(datasets), len(classifiers) + 1, i)
        clf.fit(X_train, y_train)
        score = clf.score(X_test, y_test)

        # Plot the decision boundary
        if hasattr(clf, "decision_function"):
            Z = clf.decision_function(np.c_[xx.ravel(), yy.ravel()])
        else:
            Z = clf.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]

        # Put the result into a color plot
        Z = Z.reshape(xx.shape)
        ax.contourf(xx, yy, Z, cmap=cm, alpha=0.8)

        # Plot the training points
        ax.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright, edgecolors="k")

        # Plot the testing points
        ax.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap=cm_bright, edgecolors="k", alpha=0.6)
        ax.set_xlim(xx.min(), xx.max())
        ax.set_ylim(yy.min(), yy.max())
        ax.set_xticks(())
        ax.set_yticks(())
        if ds_cnt == 0:
            ax.set_title(name)
        ax.text(xx.max() - 0.3, yy.min() + 0.3, ("%.2f" % score).lstrip("0"), size=15, horizontalalignment="right")
        i += 1

plt.tight_layout()
plt.show()

sns.scatterplot(
    x=tsne_pca_results[:, 0], y=tsne_pca_results[:, 1],
    hue=y,
    data=X,
    legend="full",
    alpha=0.3
).set(title="Feature Space Visualization of Raw Data")

"""Voilen Chart"""

seed = np.random.seed(5)
inputSize=153
dataset = pd.read_csv('/content/drive/MyDrive/vesicularnew.csv', sep=',', header=None)
#dataset=pd.read_csv('/content/drive/MyDrive/vesicularnew.csv', sep=',',header=None)
dataset = dataset.replace([np.inf, -np.inf], np.nan)
dataset = dataset.fillna(0)

for col in dataset.columns:
    dataset[col].where(dataset[col].notnull(), 0, inplace=True)

import csv
import numpy as np
from sklearn import decomposition
from sklearn.metrics import confusion_matrix, matthews_corrcoef
from sklearn.model_selection import StratifiedKFold, KFold
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn import svm
from sklearn.metrics import roc_curve
from sklearn.metrics import roc_auc_score
from sklearn.model_selection import train_test_split
import pandas as pd
from xgboost import XGBClassifier
from lightgbm import LGBMClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC
from sklearn.ensemble import BaggingClassifier, ExtraTreesClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.linear_model import RidgeClassifier, Perceptron
import pandas as pd
from sklearn.svm import LinearSVC
from sklearn.naive_bayes import GaussianNB
from sklearn.neighbors import KNeighborsClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.ensemble import  GradientBoostingClassifier, AdaBoostClassifier
import warnings
warnings.filterwarnings("ignore")

from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import StackingClassifier

len(dataset)

X

import pandas as pd

def replace_text_in_dataframe(text, replacement, dataframe):
    return dataframe.applymap(lambda x: replacement if str(x) == text else x)

search_text = '#NAME?'
replacement = 0
df_replaced = replace_text_in_dataframe(search_text, replacement, dataset)
# print(df_replaced)

import pandas as pd

# Assuming df is your DataFrame
df_replaced.columns = ['col' + str(i) for i in range(1, 524)]

# Now your columns will be named col1, col2, ..., col522
df_replaced.head()  # Display the first few rows to verify the changes
df_replaced=df_replaced.drop(0)
df_replaced

X1 = df_replaced.iloc[:, : inputSize]
Y1 = df_replaced.iloc[:, inputSize: inputSize+1]
# dataset
X1 = X1.to_numpy()
Y1 = Y1.to_numpy()

from sklearn.preprocessing import StandardScaler, MinMaxScaler
import numpy as np

std_scale = MinMaxScaler()
X1 = np.nan_to_num(X1.astype('float32'))
X1 = std_scale.fit_transform(X1)

from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import StackingClassifier

len(X1)

from sklearn.model_selection import cross_val_score
cv=5

from sklearn.model_selection import cross_val_score
cv=5
lgbm=cross_val_score(LGBMClassifier(), X, y, cv=cv)
et=cross_val_score(ExtraTreesClassifier(),X, y, cv=cv)
rf=cross_val_score(RandomForestClassifier(),X, y, cv=cv)
xgb=cross_val_score(XGBClassifier(),X, y, cv=cv)
bg=BaggingClassifier()
lsvc=LinearSVC()
lr = LogisticRegression(random_state=42)

# Define your stacking classifier with the base learners and meta-learner

st = StackingClassifier(
    estimators=[('xgb', xgbst),('et', etst),('LSVC', lsvc),('rf', rfst) ],final_estimator=lr)

lgbm

et

xgb

rf

st5=cross_val_score(st,X, y, cv=cv)

st5

# svc=cross_val_score(SVC(probability=True),X, y, cv=cv)
# st=cross_val_predict(MLPClassifier(), X, y,cv=cv,method='predict_proba')


import numpy as np
#lst_accu_stratifiedlgbm5.append(np.mean(lst_accu_stratifiedlgbm5))
st10 = {'Accuracy':[92.27, 92.4, 92.37, 91.88, 92.73],
        'folds': [1,2,3,4,5],
      'algo': 'Ensemble'}
st10=pd.DataFrame(st10)

rf10 = {'Accuracy':[91.25, 100.0, 99.97, 99.95, 100.0],
        'folds': [1,2,3,4,5],
      'algo': 'rf'}
rf10=pd.DataFrame(rf10)


lgbm10 = {'Accuracy':[77.91, 77.34, 78.49, 79.44, 78.49 ],
        'folds': [1,2,3,4,5],
      'algo': 'lgbm'}
lgbm10=pd.DataFrame(lgbm10)


xgb10 = {'Accuracy':[86.82, 85.89, 87.61, 87.53, 87.22 ],
        'folds': [1,2,3,4,5],
      'algo': 'ridge'}
xgb10=pd.DataFrame(xgb10)


# svm10 = {'Accuracy':[0.50810811, 0.57297297, 0.56216216, 0.47567568, 0.61413043],
#         'folds': [1,2,3,4,5],
#       'algo': 'svm'}
# svm10=pd.DataFrame(svm10)


et10 = {'Accuracy':[91.89, 92.7, 92.27, 92.04, 92.63],
        'folds': [1,2,3,4,5],
      'algo': 'et'}
et10=pd.DataFrame(et10)



bg10 = {'Accuracy':[87.54, 86.94, 88.17, 87.43, 86.74 ],
        'folds': [1,2,3,4,5],
      'algo': 'bg'}
bg10=pd.DataFrame(bg10)

v10 = pd.concat([rf10,et10,lgbm10,xgb10,st10,bg10], axis=0)





from matplotlib import pyplot
import seaborn
#import mylib
a4_dims = (10, 6)
#df = mylib.load_data()
fig, ax = pyplot.subplots(figsize=a4_dims,dpi=600)
seaborn.violinplot(ax=ax, y=v10["Accuracy"], x=v10["folds"])

# svc=cross_val_score(SVC(probability=True),X, y, cv=cv)
# st=cross_val_predict(MLPClassifier(), X, y,cv=cv,method='predict_proba')


import numpy as np
#lst_accu_stratifiedlgbm5.append(np.mean(lst_accu_stratifiedlgbm5))
st10 = {'Accuracy':[96.01, 95.85, 95.95, 95.39, 96.36, 95.14, 95.6, 95.49, 95.49, 95.6],
        'folds': [1,2,3,4,5,6,7,8,9,10],
      'algo': 'Ensemble'}
st10=pd.DataFrame(st10)

rf10 = {'Accuracy':[94.11,   100.0,   100.0, 100.0,   100.0,   100.0,  100.0,   100.0,  100.0,   99.95  ],
        'folds': [1,2,3,4,5,6,7,8,9,10],
      'algo': 'rf'}
rf10=pd.DataFrame(rf10)


lgbm10 = {'Accuracy':[78.3, 78.44, 78.6, 78.08, 79.37, 77.62, 76.86, 77.68, 78.29, 78.24 ],
        'folds': [1,2,3,4,5,6,7,8,9,10],
      'algo': 'lgbm'}
lgbm10=pd.DataFrame(lgbm10)


xgb10 = {'Accuracy':[87.26, 87.61, 89.45, 89.2, 89.09, 87.61, 88.27, 88.12, 89.96, 87.97],
        'folds': [1,2,3,4,5,6,7,8,9,10],
      'algo': 'ridge'}
xgb10=pd.DataFrame(xgb10)


# svm10 = {'Accuracy':[0.50810811, 0.57297297, 0.56216216, 0.47567568, 0.61413043],
#         'folds': [1,2,3,4,5],
#       'algo': 'svm'}
# svm10=pd.DataFrame(svm10)


et10 = {'Accuracy':[94.98, 94.62, 91.37, 93.86, 95.55, 95.29, 94.57, 95.24, 95.14, 95.6],
        'folds': [1,2,3,4,5,6,7,8,9,10],
      'algo': 'et'}
et10=pd.DataFrame(et10)



bgg10 = {'Accuracy':[89.25,89.66,89.55,90.32,90.68,88.63,90.07,88.94,89.5,89.71 ],
        'folds': [1,2,3,4,5,6,7,8,9,10],
      'algo': 'bg'}
bg10=pd.DataFrame(bg10)

v10 = pd.concat([rf10,et10,lgbm10,xgb10,st10,bg10], axis=0)





from matplotlib import pyplot
import seaborn
#import mylib
a4_dims = (10, 6)
#df = mylib.load_data()
fig, ax = pyplot.subplots(figsize=a4_dims,dpi=600)
seaborn.violinplot(ax=ax, y=v10["Accuracy"], x=v10["folds"])